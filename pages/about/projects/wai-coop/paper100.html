<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <title>Making Media Accessible to All - Submission for the WAI-CooP Project and the W3C APA symposium on Research and Development Questions in Digital Accessibility
  </title>
</head>

<body>
  <aside style="border: solid #900 1px; background: #ebf4f5; font-weight: bold; padding: 0.5em; margin-bottom: 3em;">This position paper is a contribution to the symposium <a href="https://www.w3.org/WAI/about/projects/wai-coop/symposium1/">"Shape the Future: Research and Development Questions in Digital Accessibility"</a>. The content of this paper was not developed
    by the W3C Web Accessibility Initiative and does not necessarily represent the consensus view of its membership.</aside>

  <h1>Making Media Accessible to All</h1>

  <ul>
    <li>Andy Quested. Chair ITU-R Working Party 6C, <a href="mailto:andy.quested@outlook.com">andy.quested@outlook.com</a></li>
    <li>Pradipta Biswas. Assistant Professor, Indian Institute of Science, <a href="mailto:pradipta@iisc.ac.in">pradipta@iisc.ac.in</a> </li>
    <li>Masahito Kawamori. Project Professor, Keio University, <a href="mailto:kawamori@sfc.wide.ad.jp">kawamori@sfc.wide.ad.jp</a> </li>
    <li>Pilar Orero. Professor of Audio-visual Translation, Universitat Autònoma de Barcelona, <a href="mailto:pilar.orero@uab.cat">pilar.orero@uab.cat</a></li>
  </ul>

  <h2>Keywords:</h2>
  <p>Personalisation, Accessible Media, User Profile</p>

  <h2>1. Problem Addressed</h2>

  <p>Selecting an accessible media service is often a binary option – either on or off, where one option is supplied to all no matter the degree or need. Audience requirements are very different and range from 100% loss of a sense to occasional need for
    assistance. Furthermore, accessible media services continue to only address sight and sound assistance, which does not help participation for those with reduce motor functions or with understanding or learning difficulties - often more than one condition
    is present leading to co-morbidity. </p>

  <p>Developers need to understand and incorporate the wide range of requirements for people with a range of abilities. A ‘one-size-fits-all’ approach can be the easiest option to implement, rather than developing different options for the same website,
    application or audiovisual media, for people with a range of abilities. Solutions are often not scalable when applied to platforms with a range of accessibility options.</p>

  <p>The role of the ITU Audio Visual Accessibility Group is to investigate and suggest options and solutions that can be applied to any form of media no matter how produced, distributed, or reproduced.</p>

  <h2>2. Relevant background</h2>

  <p>Researchers have explored ways to adapt the same content to meet the needs of different users based on a user profile. The SUPPLE project at University of Washington, IBM Web Adaptation technology and AVANTI browser are notable examples, mostly working
    for people with different range of visual and motor impairment.</p>

  <p><strong>ISO-FDIS 9241-129</strong> published a standard on managing user profiles for software individualization in 2010. The European Union Virtual User Modelling and Simulation (EU-VUMS) cluster took an ambitious attempt to publish an exhaustive set
    of anthropometric, visual, cognitive, auditory, motor and user interface related parameters for adapting man-machine interfaces of automobile, consumer electronics, audio-visual media and so on.</p>

  <p><strong>ISO/IEC 24756</strong> published the concept of Common Access Profile for accessible and assistive devices.</p>

  <p><strong>ITU Focus Group</strong> on Smart Cable Television Technical Report. ITU Study Group Work</p>

  <p><strong>ITU-T Study Group 9</strong> carries out studies on the use of telecommunication systems in the distribution of television and sound programs supporting advanced capabilities such as ultra-high definition and 3D-TV. This work covers the use
    of cable and in conjunction with other groups, hybrid networks – primarily designed for the distribution of television and sound programs to the home – as integrated broadband networks to provide interactive voice, video and data services, including
    Internet access.</p>

  <p><strong>ITU-T Study Group 16</strong> is responsible for studies relating to ubiquitous multimedia applications, multimedia capabilities for services and applications for existing and future networks, including the coordination of related studies across
    the various ITU-T SGs. It is the lead study group on multimedia video coding, systems, and applications; multimedia applications; telecommunication/ICT accessibility for persons with disabilities; human factors; intelligent transport system (ITS)
    communications; digital and e-health; Internet Protocol television (IPTV) and digital signage; and e-services.</p>

  <p><strong>ITU-R Study Group 6</strong> looks at programme production and content exchange between distributors and broadcasters and the delivery of broadcasts to users. Information on the progress of current work on some of the techniques and technologies
    related to accessibility being applied to programme production is described in ITU-R Reports (including ITU-R BT.2420 and ITU-R BT.2447). These now extend from the original Sight and Sound based accessible technologies to include haptic and cognitive
    related studies and trials. All three Study Groups have formed joint Rapporteur Group (IRG-AVA) to combine expertise and ideas with representatives from interest groups, administrations, and industry.</p>

  <h2>3. Challenges</h2>

  <p>To make media accessible to all, the entire chain from script to reproduction device must understand and contribute to the Quality of Experience of the intended audience. To cater for a diversity of needs, simple on/off systems are a very course option
    and do not take advantage of the capabilities and features new and developing technologies offer.</p>

  <p>Many of these options are not directly targeted at accessibility, technologies such as object-based media offer ideal opportunities to personalise media to a user’s needs. The challenge is to define the “language” that describes the options available
    through a personal common user profile that can be applied to any device. The standardisation of the form of such user profiles is an important objective.</p>

  <p><img src="/WAI/content-images/about/wai-coop/Fig1.png" width="90%" alt="Four horizontal bars labelled Hearing Seeing Participating and Understanding. There is a vertical line indicating the position along each bar a user can select. Under each horizontal bar there are options the user can select to enhance the content"></p>

  <p><strong><em>Fig 1. Ranges of human needs for sharing the media experience</em></strong></p>

  <p>As computer-based devices evolve, people who need assisted access to information through multiple devices will use different sets of applications and software platforms. Ideally, an accessibility service should be available on any device and application
    irrespective of underlying hardware. Responsive design of applications and web pages can be considered as an example of automatic adaptation of layout based on screen size and platform of deployment. </p>

  <p>This requires information about a user’s needs to personalize the content with respect to their range of abilities. A user profile can be defined as a representation of a user model while a user model can be defined as a machine-readable description
    of user. After creation of a single user profile a model can,</p>

  <ul>
    <li>personalize user interface and layout for different devices</li>
    <li>offer accessibility services on any device and platform</li>
    <li>share personalized interfaces across different devices and platforms</li>
    <li>adapt the quality of accessibility services (e.g., font size) across multiple devices</li>
    <li>share personalization metadata between devices. </li>
  </ul>

  <p>Examples of interface adaptation across multiple devices and platforms using a common user profile format are possible are show in Figure 2.</p>

  <p><img width="90%" src="/WAI/content-images/about/wai-coop/Fig2.png" alt="Figure 2 shows how graphics and text can be adapted and enhanced to assist visual impairment. Examples for a computer, Smart TV, Smart Phone and simple mobile phone display are shown."></p>

  <p>Figure 2. Example of interface personalization using common user profile format</p>

  <p>Profiles can save details such as color contrast, font size, inter-element spacing of icons etc. which can be applied across IP and traditional smart TVs, desktop and laptop computers, smartphones and low-end mobile devices.</p>

  <p>Developing content that can exploit a Common User Profile requires authors to explicitly state font size, color contrast for general content as well as for closed caption or subtitles. </p>

  <p>Storing and sharing information about users always bring security risks, and unintended use not authorized by the end user. Security and privacy must be fully integrated into all aspect of a Common User Profile when gathering personal information. Sharing
    of actual content is not necessary, the personalization algorithms can run on user profiles stored on local devices allowing the user to choose if and how information is shared between their own devices connected to their own secure data services.
    Standardization ensures personalization without the risk of wider sharing of an individual user’s data.</p>

  <h2>4. Outcomes</h2>

  <p>The target outcome is to provide a common data set which can describe how accessible media options are created, exchanged, distributed, and consumed by providing,</p>

  <ul>
    <li>data templates for programme makers, application designers, web, and gamming designers…</li>
    <li>allowing a Common User Profile template to be populated with personalized data</li>
    <li>enable user defined sharing of data between a user’s own devices</li>
  </ul>

  <h2>5. Future perspectives</h2>

  <p>The internet and internet connected devices have become a vital part of media. The standardisation of user profiles represents a major step toward greater media personalisation. </p>

  <p>The next step would be the automation of personalisation rather than by direct and possibly repeated human user input. Future work should include the development of AI techniques to make intelligent and adaptive service profiles that will allow the
    automatic alignment of user needs with the accessibility services available. These needs may change with content type, age of the user and the environment the user is in at the time (home, public transport, office…). The experience and needs arising
    from a live sport programme may be very different from a pre-recorded drama or a live entertainment programme. </p>

  <p>Today’s accessibility services are limited to subtitle/captions, audio description, signing and audio subtitles/captions. The future will see the development of services based on the interaction through different modalities such as haptic signalling,
    brain computer interaction (BCI), or gestures, and the interaction needs of cognitive or reduces motor. Services will make ever greater use of Machine and AI Learning. </p>

  <p>Our target is to “leave no-one behind!”.</p>

  <h2>Acknowledgements</h2>

  <p>This work has been partially funded by the European Commission funded project Media Verse: A universe of media assets and co-creation opportunities at your fingertips with the grant number 957252. Pilar Orero is part of the TransMediaCatalonia research
    group (2017SGR113).</p>

  <h2>References</h2>

  <ol>
    <li><strong>Recommendation:</strong> ITU-T Rec. H.430.1 Requirements for immersive live experience (ILE) service:
      <a href="https://www.itu.int/rec/T-REC-H.430.1-201808-I/ens">https://www.itu.int/rec/T-REC-H.430.1-201808-I/ens</a></li>
    <li><strong>Recommendation:</strong> ITU-T Rec. H.702 Accessibility profiles for IPTV systems:
      <a href="https://www.itu.int/rec/T-REC-H.702">https://www.itu.int/rec/T-REC-H.702</a></li>
    <li><strong>Technical Paper:</strong> ITU-T FSTP.WebVRI Guideline on web-based remote sign language interpretation or video remote interpretation (VRI) system:
      <a href="https://www.itu.int/myitu/-/media/Publications/2020-Publications/Guideline-on-a-web-based-VRI-system.pdf">https://www.itu.int/myitu/-/media/Publications/2020-Publications/Guideline-on-a-web-based-VRI-system.pdf</a></li>
    <li><strong>Report:</strong> ITU-R BT.2420 Collection of usage scenarios of advanced immersive sensory media systems:
      <a href="https://www.itu.int/pub/R-REP-BT.2420">https://www.itu.int/pub/R-REP-BT.2420</a></li>
    <li><strong>Report:</strong> ITU-R BT.2447 Artificial intelligence systems for programme production and exchange: <a href="https://www.itu.int/pub/R-REP-BT.2447">https://www.itu.int/pub/R-REP-BT.2447</a></li>
    <li><strong>Report:</strong> ITU-T Focus Group Technical Report of the Focus Group on Smart Cable Television: <a href="https://www.itu.int/dms_pub/itu-t/opb/fg/T-FG-SMART-2013-PDF-E.pdf">https://www.itu.int/dms_pub/itu-t/opb/fg/T-FG-SMART-2013-PDF-E.pdf</a></li>
    <li><strong>Activity:</strong> ITU-T Work Programme Common user profile format for audio-visual content distribution:
      <a href="https://www.itu.int/ITU-T/workprog/wp_item.aspx?isn=16868">https://www.itu.int/ITU-T/workprog/wp_item.aspx?isn=16868</a></li>
  </ol>




</body>

</html>